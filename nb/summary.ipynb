{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Info\n",
    "\n",
    "* What would be the similarity between Q&A problem? Can we leverage existing methods?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "\n",
    "#### Data\n",
    "* separated 20,000 instances for a development and a validation set each from training data\n",
    "* total training is 404301, which is reduced to 364301 after partitioned data.\n",
    "\n",
    "#### Preprocessing\n",
    "##### Text cleaning\n",
    "* need to look into this\n",
    "\n",
    "##### Tokenize\n",
    "* Keras provide tokenizer\n",
    "\n",
    "#### Train\n",
    "##### Word Embedding\n",
    "* a family of natural language processing techniques for mapping semantic meaning into a geographic space. word2vec nn approach.\n",
    "\n",
    "##### LSTM\n",
    "* there is a good reference. check resource section for research paper from IBM.\n",
    "\n",
    "##### 1D convolution\n",
    "\n",
    "#### Evaluation\n",
    "* log loss, AUC?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "#### resarch paper about Q&A prediction\n",
    "* https://arxiv.org/pdf/1511.04108.pdf\n",
    "* https://arxiv.org/pdf/1508.01585v2.pdf\n",
    "* http://www.mit.edu/~jonasm/info/MuellerThyagarajan_AAAI16.pdf\n",
    "* http://ben.bolte.cc/blog/2016/keras-language-modeling.html\n",
    "* https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
